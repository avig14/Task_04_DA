{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1ccfec",
   "metadata": {},
   "source": [
    "# Telco Customer Churn â€” Complete Notebook (Hints applied)\n",
    "\n",
    "This notebook follows the Task 04 hints and includes a full EDA + preprocessing + modeling workflow. It is runnable. Make sure the raw CSV `WA_Fn-UseC_-Telco-Customer-Churn.csv` is in the same folder, or use the provided cleaned/model-ready CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eea6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d480fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data (if you have the cleaned CSV)\n",
    "if os.path.exists('telco_churn_cleaned.csv'):\n",
    "    df = pd.read_csv('telco_churn_cleaned.csv')\n",
    "else:\n",
    "    df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Standardize columns\n",
    "df.columns = [c.strip().replace(' ', '_').replace('-', '_') for c in df.columns]\n",
    "# Quick fixes\n",
    "if 'TotalCharges' in df.columns:\n",
    "    df['TotalCharges'] = df['TotalCharges'].replace(' ', pd.NA)\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "\n",
    "# Create churn flag\n",
    "if 'Churn' in df.columns:\n",
    "    df['Churn_flag'] = df['Churn'].map({'Yes':1,'No':0})\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d06fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "print(df.info())\n",
    "print('\\nChurn distribution:')\n",
    "print(df['Churn_flag'].value_counts(normalize=True))\n",
    "\n",
    "# Numeric summary\n",
    "display(df.describe().T)\n",
    "\n",
    "# Check missing\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ae4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "replace_no_service = ['MultipleLines','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n",
    "for c in replace_no_service:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace({'No internet service':'No','No phone service':'No'})\n",
    "\n",
    "# Trim strings\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Save cleaned\n",
    "df.to_csv('telco_churn_cleaned.csv', index=False)\n",
    "print('Saved telco_churn_cleaned.csv')\n",
    "\n",
    "# Label encode binary-like columns\n",
    "binary_candidates = []\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    vals = df[col].dropna().unique()\n",
    "    if len(vals)==2:\n",
    "        binary_candidates.append(col)\n",
    "\n",
    "binary_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ca5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mapping for common binaries and gender\n",
    "binary_map = {'Yes':1,'No':0,'Male':1,'Female':0}\n",
    "for col in binary_candidates:\n",
    "    df[col] = df[col].map(lambda x: binary_map.get(x, x))\n",
    "\n",
    "# Prepare model dataframe\n",
    "drop_cols = [c for c in ['customerID','CustomerID','CustomerId','Churn'] if c in df.columns]\n",
    "df_model = df.drop(columns=drop_cols, errors='ignore').copy()\n",
    "\n",
    "# One-hot encode remaining object columns\n",
    "obj_cols = df_model.select_dtypes(include=['object']).columns.tolist()\n",
    "print('One-hot encoding columns:', obj_cols)\n",
    "df_model = pd.get_dummies(df_model, columns=obj_cols, drop_first=True)\n",
    "\n",
    "# Ensure target at end\n",
    "if 'Churn_flag' in df_model.columns:\n",
    "    churn = df_model.pop('Churn_flag')\n",
    "    df_model['Churn_flag'] = churn\n",
    "\n",
    "# Save model-ready\n",
    "df_model.to_csv('telco_churn_model_ready.csv', index=False)\n",
    "print('Saved telco_churn_model_ready.csv; shape=', df_model.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and scaling\n",
    "m = pd.read_csv('telco_churn_model_ready.csv')\n",
    "X = m.drop(columns=['Churn_flag'])\n",
    "y = m['Churn_flag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d57035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline models\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "print('Logistic Regression AUC:', roc_auc_score(y_test, lr.predict_proba(X_test)[:,1]))\n",
    "print(classification_report(y_test, lr.predict(X_test)))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "print('Random Forest AUC:', roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n",
    "\n",
    "# ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "lr_probs = lr.predict_proba(X_test)[:,1]\n",
    "rf_probs = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_probs)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'LR (AUC={roc_auc_score(y_test, lr_probs):.3f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RF (AUC={roc_auc_score(y_test, rf_probs):.3f})')\n",
    "plt.plot([0,1],[0,1],'--', color='grey')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.title('ROC Curves')\n",
    "plt.show()\n",
    "\n",
    "# Feature importances\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False).head(30)\n",
    "importances.plot(kind='bar', figsize=(10,4))\n",
    "plt.title('Top feature importances (RF)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scaler\n",
    "joblib.dump({'model': rf, 'scaler': scaler, 'numeric_cols': numeric_cols}, 'telco_churn_rf_model.joblib')\n",
    "print('Saved telco_churn_rf_model.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
